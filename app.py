"""
OpenReview Paper Filtering & Scoring Analysis Tool
Main Streamlit Application

A web app for filtering and analyzing papers from OpenReview
by conference, year, keywords, and review scores.
"""

import streamlit as st
from typing import List, Dict, Any
import importlib

# Force reload modules to handle hot-reloading issues
import config
import ui_components
import openreview_client
import parsing
importlib.reload(config)
importlib.reload(ui_components)
importlib.reload(openreview_client)
importlib.reload(parsing)

from parsing import (
    filter_paper_by_keywords,
    sort_papers,
)
from ui_components import (
    render_sidebar_filters,
    render_filter_summary,
    render_paper_table,
    export_papers_to_csv,
)


# ============================================================================
# PAGE CONFIG
# ============================================================================

st.set_page_config(
    page_title="OpenReview è®ºæ–‡ç­›é€‰å·¥å…·",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        color: #666;
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    mark {
        background-color: #ffeb3b !important;
        padding: 0 2px;
    }
    .stDataFrame {
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)


# ============================================================================
# SESSION STATE INITIALIZATION
# ============================================================================

def init_session_state():
    """Initialize session state variables."""
    if "papers" not in st.session_state:
        st.session_state.papers = []
    if "filtered_papers" not in st.session_state:
        st.session_state.filtered_papers = []
    if "current_page" not in st.session_state:
        st.session_state.current_page = 0
    if "data_loaded" not in st.session_state:
        st.session_state.data_loaded = False
    if "load_status" not in st.session_state:
        st.session_state.load_status = ""
    if "last_filters" not in st.session_state:
        st.session_state.last_filters = {}


init_session_state()


# ============================================================================
# DATA LOADING
# ============================================================================

def load_data(filters: Dict[str, Any]) -> None:
    """
    Load papers based on filter settings.
    Uses staged progress display for better user feedback.
    """
    # Determine what to load
    venues_to_load = []
    
    if filters["custom_venue"]:
        venues_to_load.append(("custom", filters["custom_venue"]))
    else:
        for venue in filters["venues"]:
            for year in range(filters["year_start"], filters["year_end"] + 1):
                venues_to_load.append((venue, year))
    
    if not venues_to_load:
        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªä¼šè®®æˆ–è¾“å…¥è‡ªå®šä¹‰ Venue ID")
        return
    
    all_papers = []
    status_messages = []
    total_tasks = len(venues_to_load)
    
    # Import needed modules
    from openreview_client import fetch_submissions_with_reviews
    from config import get_venue_id_candidates as get_candidates
    
    # Use st.status for staged progress display
    with st.status("ğŸ“¡ æ­£åœ¨åŠ è½½æ•°æ®ï¼ˆåŒ…å«è¯„å®¡ï¼Œçº¦éœ€ 2-3 åˆ†é’Ÿï¼‰...", expanded=True) as status:
        
        for task_idx, item in enumerate(venues_to_load):
            if item[0] == "custom":
                venue_display = item[1]
                venue_id = item[1]
                year = filters["year_start"]
            else:
                venue, year = item
                venue_display = f"{venue} {year}"
                venue_id = None
            
            # Stage 1
            st.write(f"ğŸ”— **[{task_idx + 1}/{total_tasks}] {venue_display}**")
            
            # Get venue ID candidates
            if venue_id:
                venue_ids = [venue_id]
            else:
                venue_ids = get_candidates(venue, year)
            
            papers = []
            success = False
            
            for vid in venue_ids:
                # Fetch submissions WITH reviews
                st.write(f"ğŸ“„ è·å–è®ºæ–‡å’Œè¯„å®¡æ•°æ®ï¼ˆè¯·è€å¿ƒç­‰å¾…ï¼‰...")
                fetched_papers, fetch_status = fetch_submissions_with_reviews(vid)
                
                if fetched_papers:
                    # Add year/venue info
                    for paper in fetched_papers:
                        paper["year"] = year
                        paper["venue"] = venue if not venue_id else venue_id
                    
                    papers = fetched_papers
                    
                    reviewed_count = sum(1 for p in papers if p.get("scored_review_count", 0) > 0)
                    st.write(f"âœ… æ‰¾åˆ° **{len(papers)}** ç¯‡è®ºæ–‡ï¼ˆ{reviewed_count} ç¯‡æœ‰è¯„å®¡ï¼‰")
                    status_msg = f"{venue_display}: {len(papers)} ç¯‡è®ºæ–‡ ({reviewed_count} æœ‰è¯„å®¡)"
                    status_messages.append(status_msg)
                    success = True
                    break
            
            if not success:
                st.write(f"âš ï¸ **{venue_display}** - æœªæ‰¾åˆ°æ•°æ®")
                status_messages.append(f"{venue_display}: æœªæ‰¾åˆ°æ•°æ®")
            
            all_papers.extend(papers)
        
        # Final status
        if all_papers:
            reviewed_total = sum(1 for p in all_papers if p.get("scored_review_count", 0) > 0)
            status.update(
                label=f"âœ… åŠ è½½å®Œæˆï¼{len(all_papers)} ç¯‡è®ºæ–‡ï¼ˆ{reviewed_total} ç¯‡æœ‰è¯„å®¡ï¼‰",
                state="complete",
                expanded=False
            )
        else:
            status.update(label="âŒ æœªèƒ½åŠ è½½ä»»ä½•è®ºæ–‡", state="error")
    
    # Update session state
    st.session_state.papers = all_papers
    st.session_state.data_loaded = True
    st.session_state.load_status = "\n".join(status_messages)
    st.session_state.current_page = 0


def apply_filters(papers: List[Dict[str, Any]], filters: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Apply keyword and score filters to papers.
    """
    from parsing import filter_paper_by_scores
    
    filtered = []
    
    for paper in papers:
        # Only reviewed filter
        if filters.get("only_reviewed", False):
            if paper.get("scored_review_count", 0) == 0:
                continue
        
        # Keyword filter
        if not filter_paper_by_keywords(
            paper,
            filters["keywords"],
            filters["field_scope"],
            filters["keyword_logic"]
        ):
            continue
        
        # Score filters
        if not filter_paper_by_scores(
            paper,
            min_avg_score=filters.get("min_avg_score"),
            min_max_score=filters.get("min_max_score"),
            min_review_count=filters.get("min_review_count"),
            min_confidence=filters.get("min_confidence"),
        ):
            continue
        
        filtered.append(paper)
    
    # Sort
    sorted_papers = sort_papers(filtered, filters["sort_by"], ascending=False)
    
    return sorted_papers


# ============================================================================
# MAIN APP
# ============================================================================

def main():
    """Main application entry point."""
    
    # Header
    st.markdown('<p class="main-header">ğŸ“š OpenReview è®ºæ–‡ç­›é€‰ä¸è¯„åˆ†åˆ†æ</p>', unsafe_allow_html=True)
    st.markdown(
        '<p class="sub-header">æŒ‰ä¼šè®®ã€å¹´ä»½ã€å…³é”®è¯ã€è¯„åˆ†ç­›é€‰ OpenReview è®ºæ–‡ï¼ŒæŸ¥çœ‹è¯„å®¡è¯¦æƒ…</p>',
        unsafe_allow_html=True
    )
    
    # Calculate dataset statistics for adaptive UI
    max_score_in_dataset = 10.0  # Default assumption
    if st.session_state.papers:
        # Find the absolute maximum score in the loaded dataset
        # Filter out None values
        valid_max_scores = [
            p.get("max_score") 
            for p in st.session_state.papers 
            if p.get("max_score") is not None
        ]
        
        if valid_max_scores:
            max_score_in_dataset = max(valid_max_scores)
            
            # If explicit refresh, update session state cache
            if 'max_score_dataset' not in st.session_state or st.session_state.get('data_loaded', False):
                st.session_state.max_score_dataset = max_score_in_dataset
    
    # Use cached value if available
    if 'max_score_dataset' in st.session_state:
        max_score_in_dataset = st.session_state.max_score_dataset

    # Sidebar filters
    filters = render_sidebar_filters(max_score_in_dataset=max_score_in_dataset)
    
    # Load data button in sidebar
    st.sidebar.markdown("---")
    load_clicked = st.sidebar.button(
        "ğŸ”„ åŠ è½½æ•°æ®",
        type="primary",
        use_container_width=True,
        help="ç‚¹å‡»åŠ è½½é€‰å®šä¼šè®®å’Œå¹´ä»½çš„è®ºæ–‡æ•°æ®"
    )
    
    if load_clicked:
        load_data(filters)
    
    # Clear cache button
    if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜", use_container_width=True):
        st.cache_data.clear()
        st.session_state.papers = []
        st.session_state.filtered_papers = []
        st.session_state.data_loaded = False
        st.success("ç¼“å­˜å·²æ¸…é™¤")
        st.rerun()
    
    # Main content area
    st.markdown("---")
    
    if not st.session_state.data_loaded:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©ä¼šè®®å’Œå¹´ä»½ï¼Œç„¶åç‚¹å‡»ã€ŒåŠ è½½æ•°æ®ã€æŒ‰é’®")
        
        # Show usage instructions
        with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜", expanded=True):
            st.markdown("""
            ### å¿«é€Ÿå¼€å§‹
            1. **é€‰æ‹©ä¼šè®®**: åœ¨å·¦ä¾§è¾¹æ é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªä¼šè®®ï¼ˆå¦‚ ICLR, NeurIPSï¼‰
            2. **é€‰æ‹©å¹´ä»½**: è°ƒæ•´å¹´ä»½èŒƒå›´æ»‘å—
            3. **åŠ è½½æ•°æ®**: ç‚¹å‡»ã€ŒåŠ è½½æ•°æ®ã€æŒ‰é’®
            4. **ç­›é€‰ä¸æµè§ˆ**: ä½¿ç”¨å…³é”®è¯å’Œè¯„åˆ†ç­›é€‰åŠŸèƒ½æ‰¾åˆ°æ„Ÿå…´è¶£çš„è®ºæ–‡
            
            ### æ”¯æŒçš„ä¼šè®®
            - **ICLR**: 2018-2026
            - **NeurIPS**: 2019-2026 (åˆ«å: nips)
            - **ICML**: 2023-2026
            - **AAAI**: 2023-2026
            - **AAMAS**: 2023-2026
            
            ### è‡ªå®šä¹‰ Venue
            å¦‚æœä½ çŸ¥é“ OpenReview çš„ Venue IDï¼Œå¯ä»¥ç›´æ¥åœ¨ã€Œè‡ªå®šä¹‰ Venue IDã€è¾“å…¥æ¡†ä¸­è¾“å…¥ã€‚
            ä¾‹å¦‚: `ICLR.cc/2024/Conference`
            
            ### è¯„åˆ†è¯´æ˜
            - **avg_score**: æ‰€æœ‰è¯„å®¡åˆ†æ•°çš„å¹³å‡å€¼
            - **max_score**: æ‰€æœ‰è¯„å®¡åˆ†æ•°çš„æœ€é«˜å€¼
            - **review_count**: æœ‰æ•ˆè¯„åˆ†çš„è¯„å®¡æ•°é‡
            """)
        return
    
    # Apply filters to loaded papers
    filtered_papers = apply_filters(st.session_state.papers, filters)
    st.session_state.filtered_papers = filtered_papers
    
    # Filter summary
    render_filter_summary(filters, len(filtered_papers), len(st.session_state.papers))
    
    # Export button
    col1, col2 = st.columns([3, 1])
    with col2:
        if filtered_papers:
            csv_data = export_papers_to_csv(filtered_papers)
            st.download_button(
                label="ğŸ“¥ å¯¼å‡º CSV",
                data=csv_data,
                file_name="openreview_papers.csv",
                mime="text/csv",
                use_container_width=True,
            )
    
    # Paper table
    render_paper_table(
        filtered_papers,
        st.session_state.current_page,
        filters["page_size"],
        keywords=filters["keywords"],
    )


if __name__ == "__main__":
    main()
