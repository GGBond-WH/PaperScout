"""
UI Components for OpenReview Paper Filtering Tool.
Reusable Streamlit components for the application.
"""

import streamlit as st
import pandas as pd
from typing import List, Dict, Any, Optional
from config import (
    get_available_venues,
    MIN_YEAR,
    MAX_YEAR,
    DEFAULT_PAGE_SIZE,
    MAX_DISPLAY_RESULTS,
)
from parsing import highlight_keywords, parse_keywords_input


def render_sidebar_filters(max_score_in_dataset: Optional[float] = None) -> Dict[str, Any]:
    """
    Render all sidebar filter widgets.
    
    Args:
        max_score_in_dataset: Maximum score found in the loaded dataset (for adaptive scaling)
        
    Returns:
        Dictionary containing all filter settings
    """
    st.sidebar.header("ğŸ” ç­›é€‰æ¡ä»¶")
    
    # ---- Venue Selection ----
    st.sidebar.subheader("ä¼šè®®é€‰æ‹©")
    
    available_venues = get_available_venues()
    selected_venues = st.sidebar.multiselect(
        "é€‰æ‹©ä¼šè®®ï¼ˆå¯å¤šé€‰ï¼‰",
        options=available_venues,
        default=["ICLR"],
        help="æ”¯æŒåˆ«åï¼šå¦‚è¾“å…¥ nips ä¼šè‡ªåŠ¨è¯†åˆ«ä¸º NeurIPS"
    )
    
    # Custom venue input
    custom_venue = st.sidebar.text_input(
        "è‡ªå®šä¹‰ Venue IDï¼ˆå¯é€‰ï¼‰",
        placeholder="ä¾‹å¦‚: ICLR.cc/2024/Conference",
        help="ç›´æ¥è¾“å…¥ OpenReview çš„ venue/group ID"
    )
    
    # ---- Year Selection ----
    st.sidebar.subheader("å¹´ä»½ç­›é€‰")
    
    year_range = st.sidebar.slider(
        "å¹´ä»½èŒƒå›´",
        min_value=MIN_YEAR,
        max_value=MAX_YEAR,
        value=(2024, 2024),
        help="é€‰æ‹©è¦æŸ¥è¯¢çš„å¹´ä»½èŒƒå›´"
    )
    
    # ---- Keyword Filters ----
    st.sidebar.subheader("å…³é”®è¯ç­›é€‰")
    
    keywords_input = st.sidebar.text_input(
        "å…³é”®è¯",
        placeholder="transformer attentionï¼ˆç©ºæ ¼æˆ–é€—å·åˆ†éš”ï¼‰",
        help="è¾“å…¥ä¸€ä¸ªæˆ–å¤šä¸ªå…³é”®è¯ï¼Œç”¨ç©ºæ ¼æˆ–é€—å·åˆ†éš”"
    )
    
    keyword_logic = st.sidebar.radio(
        "å…³é”®è¯é€»è¾‘",
        options=["OR", "AND"],
        horizontal=True,
        help="OR: åŒ¹é…ä»»æ„å…³é”®è¯; AND: åŒ¹é…æ‰€æœ‰å…³é”®è¯"
    )
    
    field_scope = st.sidebar.selectbox(
        "åŒ¹é…èŒƒå›´",
        options=[
            ("title_or_abstract", "æ ‡é¢˜æˆ–æ‘˜è¦"),
            ("title", "ä»…æ ‡é¢˜"),
            ("abstract", "ä»…æ‘˜è¦"),
            ("title_and_abstract", "æ ‡é¢˜ä¸”æ‘˜è¦éƒ½è¦åŒ¹é…"),
        ],
        format_func=lambda x: x[1],
        help="é€‰æ‹©å…³é”®è¯æœç´¢çš„èŒƒå›´"
    )
    
    # ---- Score Filters ----
    st.sidebar.subheader("è¯„åˆ†ç­›é€‰")
    
    # Adaptive scaling logic
    is_5_point_scale = False
    max_slider_value = 10.0
    
    if max_score_in_dataset is not None:
        # Debug: show detected max score
        # st.sidebar.caption(f"Debug: Detected max score = {max_score_in_dataset}")
        
        # Heuristic: if max score is <= 5.5, assume 5-point scale (NeurIPS 2025 style)
        if 0 < max_score_in_dataset <= 5.5:
            is_5_point_scale = True
            max_slider_value = 5.0
            st.sidebar.info(f"âš ï¸ æ£€æµ‹åˆ°æ­¤ä¼šè®®æœ€å¤§è¯„åˆ†ä¸º {max_score_in_dataset:.1f} (ç–‘ä¸º5åˆ†åˆ¶)ï¼Œå·²è‡ªåŠ¨è°ƒæ•´ç­›é€‰èŒƒå›´ã€‚")
        elif max_score_in_dataset > 5.5:
             # Just to be sure, show if it's high
             pass
    
    # Helper to prevent error if session state has value > max_slider_value
    def clamp_session_value(key, max_val):
        if key in st.session_state and st.session_state[key] > max_val:
            st.session_state[key] = 0.0
            
    # Clamp values for all score inputs
    clamp_session_value('min_avg_score_input', max_slider_value)
    clamp_session_value('min_max_score_input', max_slider_value)
    
    min_avg_score = st.sidebar.number_input(
        f"æœ€ä½å¹³å‡åˆ† (avg_score â‰¥) - ä¸Šé™ {max_slider_value}",
        min_value=0.0,
        max_value=max_slider_value,
        value=0.0 if not is_5_point_scale else min(st.session_state.get('min_avg_score_input', 0.0), max_slider_value),
        step=0.5,
        help="ç­›é€‰å¹³å‡è¯„åˆ†å¤§äºç­‰äºæ­¤å€¼çš„è®ºæ–‡",
        key='min_avg_score_input'
    )
    
    min_max_score = st.sidebar.number_input(
        f"æœ€ä½æœ€é«˜åˆ† (max_score â‰¥) - ä¸Šé™ {max_slider_value}",
        min_value=0.0,
        max_value=max_slider_value,
        value=0.0 if not is_5_point_scale else min(st.session_state.get('min_max_score_input', 0.0), max_slider_value),
        step=0.5,
        help="ç­›é€‰æœ€é«˜è¯„åˆ†å¤§äºç­‰äºæ­¤å€¼çš„è®ºæ–‡",
        key='min_max_score_input'
    )
    
    min_review_count = st.sidebar.number_input(
        "æœ€å°‘è¯„å®¡æ•° (scored_review_count â‰¥)",
        min_value=0,
        max_value=10,
        value=0,
        step=1,
        help="ç­›é€‰è‡³å°‘æœ‰Nä¸ªæœ‰æ•ˆè¯„åˆ†çš„è®ºæ–‡"
    )
    
    # Optional: confidence filter
    with st.sidebar.expander("é«˜çº§ç­›é€‰ï¼ˆç½®ä¿¡åº¦ï¼‰"):
        min_confidence = st.number_input(
            "æœ€ä½å¹³å‡ç½®ä¿¡åº¦",
            min_value=0.0,
            max_value=5.0,
            value=0.0,
            step=0.5,
            help="ç­›é€‰è¯„å®¡ç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"
        )
    
    # Quick filter for reviewed papers only
    only_reviewed = st.sidebar.checkbox(
        "åªæ˜¾ç¤ºæœ‰è¯„å®¡çš„è®ºæ–‡",
        value=True,
        help="å‹¾é€‰ååªæ˜¾ç¤ºæœ‰è¯„åˆ†è®°å½•çš„è®ºæ–‡ï¼ŒåŠ å¿«ç­›é€‰é€Ÿåº¦"
    )
    
    # ---- Sorting ----
    st.sidebar.subheader("æ’åº")
    
    sort_options = [
        ("avg_score", "å¹³å‡åˆ† (é«˜â†’ä½)"),
        ("max_score", "æœ€é«˜åˆ† (é«˜â†’ä½)"),
        ("scored_review_count", "è¯„å®¡æ•° (å¤šâ†’å°‘)"),
        ("year", "å¹´ä»½ (æ–°â†’æ—§)"),
        ("title", "æ ‡é¢˜å­—æ¯åº"),
    ]
    
    sort_by = st.sidebar.selectbox(
        "æ’åºæ–¹å¼",
        options=sort_options,
        format_func=lambda x: x[1],
    )
    
    # ---- Display Settings ----
    st.sidebar.subheader("æ˜¾ç¤ºè®¾ç½®")
    
    page_size = st.sidebar.selectbox(
        "æ¯é¡µæ˜¾ç¤ºæ•°é‡",
        options=[20, 50, 100, 200],
        index=1,
    )
    
    # Parse keywords
    keywords = parse_keywords_input(keywords_input)
    
    return {
        "venues": selected_venues,
        "custom_venue": custom_venue.strip(),
        "year_start": year_range[0],
        "year_end": year_range[1],
        "keywords": keywords,
        "keyword_logic": keyword_logic,
        "field_scope": field_scope[0],
        "min_avg_score": min_avg_score if min_avg_score > 0 else None,
        "min_max_score": min_max_score if min_max_score > 0 else None,
        "min_review_count": min_review_count if min_review_count > 0 else None,
        "min_confidence": min_confidence if min_confidence > 0 else None,
        "only_reviewed": only_reviewed,
        "sort_by": sort_by[0],
        "page_size": page_size,
    }


def render_filter_summary(filters: Dict[str, Any], result_count: int, total_count: int):
    """
    Display current filter summary and result count.
    """
    cols = st.columns([3, 1])
    
    with cols[0]:
        summary_parts = []
        
        if filters["venues"]:
            summary_parts.append(f"**ä¼šè®®**: {', '.join(filters['venues'])}")
        if filters["custom_venue"]:
            summary_parts.append(f"**è‡ªå®šä¹‰**: {filters['custom_venue']}")
        
        summary_parts.append(f"**å¹´ä»½**: {filters['year_start']}-{filters['year_end']}")
        
        if filters["keywords"]:
            kw_str = ", ".join(filters["keywords"])
            summary_parts.append(f"**å…³é”®è¯**: {kw_str} ({filters['keyword_logic']})")
        
        if filters["min_avg_score"]:
            summary_parts.append(f"**å¹³å‡åˆ†â‰¥**: {filters['min_avg_score']}")
        if filters["min_max_score"]:
            summary_parts.append(f"**æœ€é«˜åˆ†â‰¥**: {filters['min_max_score']}")
        
        st.markdown(" | ".join(summary_parts))
    
    with cols[1]:
        st.metric("åŒ¹é…ç»“æœ", f"{result_count} / {total_count}")


def render_paper_table(
    papers: List[Dict[str, Any]], 
    page: int, 
    page_size: int,
    keywords: List[str] = None,
) -> None:
    """
    Render paginated paper table with expandable details.
    """
    if not papers:
        st.info("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®ºæ–‡ã€‚è¯·è°ƒæ•´ç­›é€‰æ¡ä»¶ã€‚")
        return
    
    # Pagination
    total_papers = len(papers)
    total_pages = (total_papers + page_size - 1) // page_size
    
    start_idx = page * page_size
    end_idx = min(start_idx + page_size, total_papers)
    page_papers = papers[start_idx:end_idx]
    
    # Page navigation
    if total_pages > 1:
        cols = st.columns([1, 3, 1])
        with cols[0]:
            if st.button("â—€ ä¸Šä¸€é¡µ", disabled=page == 0):
                st.session_state.current_page = page - 1
                st.rerun()
        with cols[1]:
            st.markdown(f"<center>ç¬¬ {page + 1} / {total_pages} é¡µ (å…± {total_papers} æ¡)</center>", unsafe_allow_html=True)
        with cols[2]:
            if st.button("ä¸‹ä¸€é¡µ â–¶", disabled=page >= total_pages - 1):
                st.session_state.current_page = page + 1
                st.rerun()
    
    # Create summary dataframe
    df_data = []
    for paper in page_papers:
        authors_str = ", ".join(paper.get("authors", [])[:3])
        if len(paper.get("authors", [])) > 3:
            authors_str += f" +{len(paper['authors']) - 3} more"
        
        df_data.append({
            "æ ‡é¢˜": paper.get("title", "Untitled"),
            "ä¼šè®®/å¹´ä»½": f"{paper.get('venue', '')} {paper.get('year', '')}",
            "ä½œè€…": authors_str,
            "å¹³å‡åˆ†": f"{paper.get('avg_score', '-'):.1f}" if paper.get('avg_score') else "-",
            "æœ€é«˜åˆ†": f"{paper.get('max_score', '-'):.1f}" if paper.get('max_score') else "-",
            "è¯„å®¡æ•°": paper.get("scored_review_count", 0),
        })
    
    df = pd.DataFrame(df_data)
    st.dataframe(df, use_container_width=True, hide_index=True)
    
    # Expandable details for each paper
    st.markdown("---")
    st.subheader("ğŸ“„ è®ºæ–‡è¯¦æƒ…")
    
    for i, paper in enumerate(page_papers):
        render_paper_expander(paper, keywords, idx=start_idx + i + 1)


def render_paper_expander(
    paper: Dict[str, Any], 
    keywords: List[str] = None,
    idx: int = 0
) -> None:
    """
    Render expandable paper details.
    """
    title = paper.get("title", "Untitled")
    avg_score = paper.get("avg_score")
    score_str = f"â­ {avg_score:.1f}" if avg_score else "æ— è¯„åˆ†"
    
    with st.expander(f"**{idx}. {title}** ({score_str})"):
        # Links row
        cols = st.columns([2, 1, 1])
        with cols[0]:
            st.markdown(f"**ä¼šè®®**: {paper.get('venue', '')} {paper.get('year', '')}")
        with cols[1]:
            openreview_url = paper.get("openreview_url", "")
            if openreview_url:
                st.markdown(f"[ğŸ”— OpenReview]({openreview_url})")
        with cols[2]:
            pdf_url = paper.get("pdf_url", "")
            if pdf_url:
                st.markdown(f"[ğŸ“„ PDF]({pdf_url})")
        
        # Authors
        authors = paper.get("authors", [])
        if authors:
            authors_str = ", ".join(authors)
            st.markdown(f"**ä½œè€…**: {authors_str}")
        
        # Keywords (from paper metadata)
        paper_keywords = paper.get("keywords", [])
        if paper_keywords:
            st.markdown(f"**å…³é”®è¯**: {', '.join(paper_keywords)}")
        
        # TL;DR
        tldr = paper.get("tldr", "")
        if tldr:
            st.markdown(f"**TL;DR**: {tldr}")
        
        # Abstract with keyword highlighting
        abstract = paper.get("abstract", "")
        if abstract:
            st.markdown("**æ‘˜è¦**:")
            if keywords:
                abstract_html = highlight_keywords(abstract, keywords)
                st.markdown(abstract_html, unsafe_allow_html=True)
            else:
                st.markdown(abstract)
        
        # Score summary
        st.markdown("---")
        st.markdown("**è¯„åˆ†ç»Ÿè®¡**")
        score_cols = st.columns(4)
        with score_cols[0]:
            st.metric("å¹³å‡åˆ†", f"{paper.get('avg_score', '-'):.1f}" if paper.get('avg_score') else "-")
        with score_cols[1]:
            st.metric("æœ€é«˜åˆ†", f"{paper.get('max_score', '-'):.1f}" if paper.get('max_score') else "-")
        with score_cols[2]:
            st.metric("æœ€ä½åˆ†", f"{paper.get('min_score', '-'):.1f}" if paper.get('min_score') else "-")
        with score_cols[3]:
            st.metric("è¯„å®¡æ•°", paper.get("scored_review_count", 0))
        
        # Individual reviews
        reviews = paper.get("reviews", [])
        if reviews:
            st.markdown("**è¯„å®¡è¯¦æƒ…**")
            for j, review in enumerate(reviews):
                content = review.get("content", {})
                
                # Extract display info
                review_info = []
                for key in ["rating", "recommendation", "score", "confidence"]:
                    if key in content:
                        val = content[key]
                        if isinstance(val, dict) and "value" in val:
                            val = val["value"]
                        review_info.append(f"{key}: {val}")
                
                if review_info:
                    st.markdown(f"- **Review {j+1}**: {' | '.join(review_info)}")


def export_papers_to_csv(papers: List[Dict[str, Any]]) -> bytes:
    """
    Convert papers to CSV format for download.
    """
    export_data = []
    for paper in papers:
        export_data.append({
            "Title": paper.get("title", ""),
            "Venue": paper.get("venue", ""),
            "Year": paper.get("year", ""),
            "Authors": "; ".join(paper.get("authors", [])),
            "Abstract": paper.get("abstract", ""),
            "Keywords": "; ".join(paper.get("keywords", [])),
            "Avg Score": paper.get("avg_score", ""),
            "Max Score": paper.get("max_score", ""),
            "Min Score": paper.get("min_score", ""),
            "Review Count": paper.get("scored_review_count", 0),
            "Avg Confidence": paper.get("avg_confidence", ""),
            "OpenReview URL": paper.get("openreview_url", ""),
            "PDF URL": paper.get("pdf_url", ""),
        })
    
    df = pd.DataFrame(export_data)
    return df.to_csv(index=False).encode('utf-8')


def render_loading_progress() -> None:
    """
    Create a placeholder for loading progress.
    """
    return st.empty()
